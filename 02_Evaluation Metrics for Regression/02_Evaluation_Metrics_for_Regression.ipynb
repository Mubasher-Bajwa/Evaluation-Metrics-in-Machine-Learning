{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mean Absolute Error (MAE):\n",
    "#### It is the average of the absolute differences between the actual value and the model’s predicted value.\n",
    "#### If we don’t take the absolute values, then the negative difference will cancel out the positive difference and we will be left with a zero upon summation.\n",
    "\n",
    "#### A small MAE suggests the model is great at prediction, while a large MAE suggests that your model may have trouble in certain areas. MAE of 0 means that your model is a perfect predictor of the outputs.\n",
    "\n",
    "#### Here’s a Scikit-learn implementation of MAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_test = [3, 5, 2, 7] \n",
    "y_pred = [2, 0, 2, 8]\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us do some calculations here, the difference between these data is 1,5,0,1 (i.e  1+5+0+1) which gives you 7. Then the average is taken where n=4, so 7/4 gives you (1.75).\n",
    "#### The best score here would be 0.\n",
    "\n",
    "#### The mean absolute error (MAE) has the same unit as the original data, and it can only be compared between models whose errors are measured in the same units.\n",
    "\n",
    "#### The bigger the MAE, the more critical the error is. It is robust to outliers. Therefore, by taking the absolute values, MAE can deal with the outliers\n",
    "\n",
    "#### Here, a big error doesn’t overpower a lot of small errors and thus the output provides us with a relatively unbiased understanding of how the model is performing. Hence, it fails to punish the bigger error terms.\n",
    "\n",
    "#### MAE is not differentiable so we have to apply various optimizers like Gradient descent which can be differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mean Squared Error (MSE):\n",
    "#### It is the average of the squared differences between the actual and the predicted values.\n",
    "\n",
    "#### Lower the value, the better the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_test = [3, 5, 2, 7] \n",
    "y_pred = [2, 0, 2, 8]\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same inputs similar to above mean absolute error is given to this mean squared error, where the difference in the data is ( 1 square+5 square+0 square+1 square) = 27 and mean is (27/4) which gives the output.\n",
    "\n",
    "#### If you have outliers in the dataset then it penalizes the outliers most and the calculated MSE is bigger. So, in short, It is not Robust to outliers which were an advantage in MAE.\n",
    "\n",
    "#### MSE uses the square operation to remove the sign of each error value and to punish large errors.\n",
    "\n",
    "#### As we take the square of the error, the effect of larger errors become more pronounced then smaller error, hence the model can now focus more on the larger errors.\n",
    "\n",
    "#### The main reason this is not that useful is that if we make a single very bad prediction, the squaring will make the error even worse and it may skew the metric towards overestimating the model’s badness.\n",
    "\n",
    "#### On the other hand, if all the errors are small, or rather, smaller than 1, then we may underestimate the model’s badness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Root Mean Squared Error (RMSE):\n",
    "#### It is the average root-squared difference between the real value and the predicted value. By taking a square root of MSE, we get the Root Mean Square Error.\n",
    "\n",
    "#### We want the value of RMSE to be as low as possible, as lower the RMSE value is, the better the model is with its predictions. A Higher RMSE indicates that there are large deviations between the predicted and actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2.598076211353316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_test = [3, 5, 2, 7] \n",
    "y_pred = [2, 0, 2, 8]\n",
    "print(\"Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same inputs similar to above mean squared error is given to this mean squared error by keeping the 'squared' = False, where the difference in the data is ( 1 square+5 square+0 square+1 square) = 27 and mean is (27/4)=6.75 and taking its square root which gives the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Max Error:\n",
    "#### While RMSE is the most common metric, it can be hard to interpret. One alternative is to look at quantiles of the distribution of the absolute percentage errors. The Max-Error metric is the worst-case error between the predicted value and the true value.\n",
    "\n",
    "#### It calculates the maximum error present between the original data and predicted data,\n",
    "Where it compares and finds out data that has the maximum difference and produces the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Error 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import max_error\n",
    "y_test = [8, 4, 7, 1]\n",
    "y_pred = [4, 2, 7, 1]\n",
    "print(\"Max Error\", max_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above code, the original data is compared with predicted data, where the maximum difference occurred between data 8 and 4 so the output is the difference between them (i.e  4).\n",
    "#### The best output possible here is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. R² score, the coefficient of determination:\n",
    "\n",
    "This is the most important evaluation metric in the regression evaluation where it gives us an understanding of how well the data get fit towards the regression line. This helps us to find the relationship between the independent variable towards the dependent variable.\n",
    "R-squared explains to what extent the variance of one variable explains the variance of the second variable. In other words, it measures the proportion of variance of the dependent variable explained by the independent variable.\n",
    "\n",
    "R squared is a popular metric for identifying model accuracy. It tells how close are the data points to the fitted line generated by a regression algorithm. A larger R squared value indicates a better fit. This helps us to find the relationship between the independent variable towards the dependent variable.\n",
    "\n",
    "R² score ranges from 0 to 1. The closest to 1 the R², the better the regression model is. If R² is equal to 0, the model is not performing better than a random model. If R² is negative, the regression model is erroneous.\n",
    "\n",
    "It is the ratio of the sum of squares and the total sum of squares\n",
    "## R2 = 1 - SSE/SST\n",
    "### where SSE is the sum of the square of the difference between the actual value and the predicted value\n",
    "### and, SST is the total sum of the square of the difference between the actual value and the mean of the actual value.\n",
    "\n",
    "When we add new features in our data, R2 score starts increasing or constant but never decreases because It assumes that while adding more data variance of data increases.\n",
    "\n",
    "But the problem is when we add an irrelevant feature in the dataset then at that time R2 sometimes starts increasing which is incorrect.\n",
    "\n",
    "Here’s a Scikit-learn implementation of R2 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.23076923076923073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test = [8, 5, 1, 6]\n",
    "y_pred = [7, 8, 2, 3]\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 describes the proportion of variance of the dependent variable explained by the regression model. If the regression model is “perfect”, SSE is zero, and R2 is 1. If the regression model is a total failure, SSE is equal to SST, no variance is explained by the regression, and R2 is zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd275371c28e8315e03adf8b037f110cb1b8ea1df403d06bca1b2c33c8fa2b88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
